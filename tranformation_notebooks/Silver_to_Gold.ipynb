{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3d4de2-78a4-4fb3-a837-9acfe6bd98ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# No need to reintall if was installed in previous notebook on same cluster\n",
    "%pip install /dbfs/FileStore/libs/common_stock_classes-0.1.0-py3-none-any.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9475c388-f5d7-4bdf-9b38-96da67eab19b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from common_stock_classes  import  HelperMethods # ,SCDType2Handler\n",
    "from pyspark.sql.functions import col, explode, monotonically_increasing_id, lit, cast , concat, expr, date_format, sha2, concat_ws, sequence\n",
    "from pyspark.sql.types import DateType, TimestampType   # sha2,concat_ws,trim, lit\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import date, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e39817-1746-4f5a-8ebc-8b6b16bc1792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initiate Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e588cb-6069-431d-a0a4-0652565a37cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/andrewkravchuk@outlook.com/azure-stock-market/tranformation_notebooks/temp_SCDType2Handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0142ac-abb1-4e88-9d79-f39988c882b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "silver_path = \"abfss://silver@andrewstockmarket.dfs.core.windows.net/delta-tables/main\"  # Target location for Silver Delta table\n",
    "dim_symbol_path = \"abfss://gold@andrewstockmarket.dfs.core.windows.net/delta-tables/dim-symbol\"\n",
    "fact_daily_path = \"abfss://gold@andrewstockmarket.dfs.core.windows.net/delta-tables/fact-daily-summary\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b81bd35a-15b3-4b48-a28a-6dc931d3a45c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# silver_path = \"/Users/PC/Desktop/VS Code Repositories/azure-stock-market/Azure storage/Silver/delta-table\"  # Target location for Silver Delta table\n",
    "\n",
    "# df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "# df_silver.createOrReplaceTempView(\"stemp\")\n",
    "\n",
    "# spark.sql(\"select * from stemp\").limit(2).show()\n",
    "\n",
    "\n",
    "# silver_df = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "# spark.sql( f\"delete from delta.`{silver_path}` where __Hashkey like '%c%' \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d4942b8-d2d1-43ca-88f3-06856cf94aef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dim Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528f2cf6-6b7c-4ad1-84cc-27edffeda7de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameters = {\n",
    "        \"businessColumns\" : \"Symbol,ExchangeName,Currency\",\n",
    "        \"typeIColumns\" : \"\", \n",
    "        \"tableType\" : \"Dim\"\n",
    "        }\n",
    "scd2Handler =  SCDType2Handler(parameters)\n",
    "\n",
    "\n",
    "\n",
    "df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "df_dimSymbol =  df_silver.select(\"Symbol\",\"ExchangeName\",\"Currency\", \"Type\", \"ExchangeTimeZone\").distinct()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scd2Handler.refresh_timestamp()\n",
    "\n",
    "# df_dimSymbol = df_dimSymbol.withColumn(\"Type\", concat(col(\"Type\"), lit(\"_test\") ) )\n",
    "\n",
    "\n",
    "add_audit_columns =  scd2Handler.add_audit_columns\n",
    "\n",
    "\n",
    "df_dimSymbol = df_dimSymbol.transform(add_audit_columns)\n",
    "\n",
    "\n",
    "\n",
    "# sid_offest = spark.read.format(\"delta\").load(dim_symbol_path)\n",
    "\n",
    "\n",
    "# sid_offest = sid_offest.selectExpr(\"max(SymbolSID)\").head()[0]\n",
    "\n",
    "# sid_offest = sid_offest + 1 if sid_offest else 0\n",
    "\n",
    "\n",
    "\n",
    "# df_dimSymbol = df_dimSymbol.withColumn(\"SymbolSID\", monotonically_increasing_id() +  sid_offest)\n",
    "\n",
    "# spark.read.format(\"delta\").load(dim_symbol_path).show()\n",
    "\n",
    "display(df_dimSymbol)\n",
    "\n",
    "\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, dim_symbol_path)\n",
    "scd2Handler.delta_merge_typeII(deltaTable, df_dimSymbol)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef46a680-0d16-4b11-8092-7fc1af953362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_history = spark.sql(f\" select *  from  delta.`{dim_symbol_path}`  \")\n",
    "# df_history = spark.sql(f\" delete   from  delta.`{fact_daily_path}`  \")\n",
    "# df_history = spark.sql(f\" delete   from  delta.`{dim_symbol_path}`  \")\n",
    "\n",
    "  \n",
    "display(df_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20d4a868-bcb7-4a3e-a1f6-15d726de1bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fact Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4abe9306-6b82-41f5-bad7-4a265cca6339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "df_fact =  df_silver # .select(\"Volume\",\"High\",\"Low\", \"Close\", \"Open\",\"Date\")\n",
    "df_fact =  df_fact.withColumn(\"DateID\", date_format(col(\"Date\"), \"yyyyMMdd\").cast(\"int\")).drop(\"Date\")\n",
    "\n",
    "\n",
    "# Add Hash Key for Dim Symbol \n",
    "\n",
    "businessColumns  = [\"Symbol\", \"ExchangeName\", \"Currency\"] \n",
    "\n",
    "df_fact = df_fact.withColumn(\"DimSymbolBusinessHash\" , sha2( concat_ws(\"|\", *businessColumns), 256))\n",
    "\n",
    "\n",
    "\n",
    "df_dim_symbol = spark.table(f\"delta.`{dim_symbol_path}` \")\n",
    "\n",
    "df_fact = df_fact.alias(\"f\").join(df_dim_symbol.alias(\"d\"), on = expr(\"f.DimSymbolBusinessHash = d.__BusinessKeyHash\"), how = \"left\" ) \\\n",
    "                .where(\"d.__CurrentFlag = true\") \\\n",
    "                .selectExpr(\"d.SymbolSID\", \n",
    "                            \"f.Volume\", \n",
    "                            \"f.High\",\n",
    "                            \"f.Low\",\n",
    "                            \"f.Open\",\n",
    "                            \"f.Close\",\n",
    "                            \"f.DateID\"\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "        \"businessColumns\" : \"Symbol,ExchangeName,Currency\",\n",
    "        \"typeIColumns\" : \"\", \n",
    "        \"tableType\" : \"Fact\"\n",
    "        }\n",
    "\n",
    "scd2Handler =  SCDType2Handler(parameters)\n",
    "\n",
    "\n",
    "scd2Handler.refresh_timestamp()\n",
    "add_audit_columns =  scd2Handler.add_audit_columns\n",
    "df_fact = df_fact.transform(add_audit_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, fact_daily_path)\n",
    "\n",
    "scd2Handler.delta_merge_typeII(deltaTable, df_fact)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0dc2ad-852c-4758-be26-caf1681b48e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_history = spark.sql(f\" select  *  from  delta.`{fact_daily_path}`\")\n",
    "\n",
    "# df_history = spark.sql(f\" delete   from  delta.`{fact_daily_path}`  \")\n",
    "\n",
    "  \n",
    "display(df_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b93a5e4-4904-4766-896b-9497a96ec412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# parameters = {\n",
    "#         \"businessColumns\" : \"Symbol,ExchangeName,Currency\",\n",
    "#         \"typeIColumns\" : \"\", \n",
    "#         \"tableType\" : \"Dim\"\n",
    "#         }\n",
    "# scd2Handler =  SCDType2Handler(parameters)\n",
    "\n",
    "\n",
    "\n",
    "# silver_path = \"/Users/PC/Desktop/VS Code Repositories/azure-stock-market/Azure storage/Silver/delta-table\"  # Target location for Silver Delta table\n",
    "\n",
    "# df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "# df_dimSymbol =  df_silver.select(\"Symbol\",\"ExchangeName\",\"Currency\", \"Type\", \"ExchangeTimeZone\").distinct()\n",
    "\n",
    "# dim_symbol_path = \"/Users/PC/Desktop/VS Code Repositories/azure-stock-market/Azure storage/Gold/delta-tables/dim-symbol\"\n",
    "\n",
    "\n",
    "\n",
    "# scd2Handler.refresh_timestamp()\n",
    "\n",
    "# # df_dimSymbol = df_dimSymbol.withColumn(\"Type\", concat(col(\"Type\"), lit(\"_test\") ) )\n",
    "\n",
    "# add_audit_columns =  scd2Handler.add_audit_columns\n",
    "# df_dimSymbol = df_dimSymbol.transform(add_audit_columns)\n",
    "\n",
    "\n",
    "\n",
    "# sid_offest = spark.read.format(\"delta\").load(dim_symbol_path)\n",
    "\n",
    "\n",
    "# sid_offest = sid_offest.selectExpr(\"max(Symbol_SID)\").head()[0]\n",
    "\n",
    "# sid_offest = sid_offest + 1 if sid_offest else 0\n",
    "\n",
    "\n",
    "\n",
    "# df_dimSymbol = df_dimSymbol.withColumn(\"Symbol_SID\", monotonically_increasing_id() +  sid_offest)\n",
    "\n",
    "# spark.read.format(\"delta\").load(dim_symbol_path).show()\n",
    "\n",
    "# df_dimSymbol.show(truncate=False)\n",
    "# deltaTable = DeltaTable.forPath(spark, dim_symbol_path)\n",
    "# scd2Handler.delta_merge_typeII(deltaTable, df_dimSymbol)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96ede9c6-8721-4332-bfe0-248591ab4f9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "start_date = date.fromisoformat('2000-01-01')\n",
    "end_date = date.fromisoformat('2010-01-01')\n",
    "\n",
    "\n",
    "    # 1. Build a 1‑row DataFrame just so we can call sequence(…)\n",
    "bounds = spark.range(1).withColumn(\"dates_list\", sequence( lit(start_date), lit(end_date), expr(\"interval 1 day\")))\n",
    "\n",
    "display(bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6437463c-2306-4a2c-bc09-05231093fb91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Populate Dim Table if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17674d25-cdd7-4216-9fb1-b0da6b89ce7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hm = HelperMethons(spark=spark)\n",
    "dimDate_folder =  \"/Users/PC/Desktop/VS Code Repositories/azure-stock-market/Azure storage/Gold/delta-tables/dim-date\"\n",
    "df_dimdate = spark.read.format(\"delta\").load(dimDate_folder)\n",
    "\n",
    "\n",
    "max_date_dimDate =  df_dimdate.selectExpr(\" cast(max(date) as date) as max_date\").head()[0]\n",
    "min_date_silver =  df_silver.selectExpr(\" cast(min(date) as date) as min_date\").head()[0]\n",
    "max_date_silver =  df_silver.selectExpr(\" cast(max(date) as date) as max_date\").head()[0]\n",
    "\n",
    "\n",
    "\n",
    "## populate DimDate table if we dont have records with dates \n",
    "if min_date_silver > max_date_dimDate:\n",
    "    \n",
    "    start_date = max_date_dimDate + timedelta(days=1)\n",
    "    end_date =  date( max_date_silver.year , 12, 31)\n",
    "    \n",
    "    hm.update_DimDate_fromRange(start_date, end_date )\n",
    "    print(f\"Dim Table Updated with date range [ {start_date} : {end_date} ] \")\n",
    "    \n",
    "    \n",
    "df_dimdate = spark.read.format(\"delta\").load(dimDate_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a1a3895-d7a2-4958-8aae-e6ec2d207fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8161991b-8e47-4640-86b4-fc9aa294cc39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00bf3bfe-6fd9-4101-9604-57a874264555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6a28ba7-034d-451e-809a-3baeac151997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a5c1fa-7164-4865-82b2-b27405e27591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d44135e3-6eb9-4808-bbce-59963885fab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Get Data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29b8b639-9d53-4d05-b35f-22b43fec667f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bronze -> Silver"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_to_Gold",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
