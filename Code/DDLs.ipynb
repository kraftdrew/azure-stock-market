{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2475043-1710-4d06-8dbf-79c8483fb29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bronze_container = \"abfss://bronze@andrewstockmarket.dfs.core.windows.net/\"  # Bronze data stored in Parquet or Delta\n",
    "silver_container = \"abfss://silver@andrewstockmarket.dfs.core.windows.net/\"  # Target location for Silver Delta table\n",
    "gold_container = \"abfss://gold@andrewstockmarket.dfs.core.windows.net/\"  # Target location for Silver Delta table\n",
    "\n",
    "\n",
    "# Your Delta folder path\n",
    "silver_path =   silver_container + \"delta-tables/main\"\n",
    "dimSymbol_path = gold_container + \"delta-tables/dim-symbol\"\n",
    "dimDate_path = gold_container + \"delta-tables/dim-date\"\n",
    "fact_path =  gold_container + \"delta-tables/fact-daily-summary\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## re-create table \n",
    "# truncate_schema = spark.read.format(\"delta\").load(silver_path).schema\n",
    "# truncate_silver = spark.createDataFrame([], schema= truncate_schema)\n",
    "# truncate_silver.write.format(\"delta\").mode(\"overwrite\").save(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e947a60-c485-4e61-8a8d-18ded38e4d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    " \n",
    "-- use  schema silver \n",
    "-- drop  schema   if  exists hive_metastore.silver cascade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc73772a-98ae-42ed-b27e-4d3eb9dd2d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "show  CATALOGs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d32d9c2c-455f-40f9-846d-39bef5049ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adb5d455-6ad6-4f09-985b-040352eb0923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql( \"\"\"\n",
    "CREATE EXTERNAL LOCATION gold\n",
    "URL 'abfss://gold@andrewstockmarket.dfs.core.windows.net/'\n",
    "WITH (STORAGE CREDENTIAL dev_credentials)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affe49f4-e058-4421-a411-97a65601748f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# catalog = \"hive_metastore\" \n",
    "# schema_list = [\"silver\", \"gold\"]  \n",
    "\n",
    "# for schema in schema_list:\n",
    "        \n",
    "#        tables = spark.sql(f\"show tables in {catalog}.{schema}\").collect()\n",
    "\n",
    "#        for table in tables :\n",
    "#            if not table.isTemporary:  \n",
    "#             print(table.isTemporary)\n",
    "#             display(spark.sql(f\"DESCRIBE EXTENDED  {catalog}.{schema}.{table.tableName}\"))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7825f93d-80e7-433a-b5e6-1dfb8d67814e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf47c20a-d663-4a69-bc4f-9186ef3fed76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table  stocks.silver.silver_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36ab4f7c-de91-4c8e-b9ce-12067e5f04a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE stocks.silver.silver_table (\n",
    "    Symbol                   STRING,\n",
    "    ExchangeName             STRING,\n",
    "    Currency                 STRING,\n",
    "    Type                     STRING,\n",
    "    ExchangeTimeZone         STRING,\n",
    "    Volume                   INTEGER,\n",
    "    High                     DECIMAL,\n",
    "    Low                      DECIMAL,\n",
    "    Close                    DECIMAL,\n",
    "    Open                     DECIMAL,\n",
    "    Date                     DATE,\n",
    "    __CurrentFlag            BOOLEAN,\n",
    "    __DeletedFlag            BOOLEAN,\n",
    "    __EffectiveStartDateTime TIMESTAMP,\n",
    "    __EffectiveEndDateTime   TIMESTAMP,\n",
    "    __lastmodified           TIMESTAMP,\n",
    "    __HashKey                STRING,\n",
    "    __HashValue              STRING,\n",
    "    __CreatedBatchLogId      STRING,\n",
    "    __UpdatedBatchLogId      STRING,\n",
    "    __CreateDateTime         TIMESTAMP,\n",
    "    __UpdateDateTime         TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{silver_path}'\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "845d7884-bcb0-429b-8417-219fc9686694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 3) Verify registration and schema\n",
    "# display( spark.sql(\"SHOW TABLES\"))\n",
    "# display( spark.sql(\"DESCRIBE silver.silver_table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a300e64-3445-4a07-bae3-c6f4a302bf8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dim Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504a2289-e392-4e2c-95cc-e400acdec383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2) Create the table with full schema, pointing at that folder\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE stocks.gold.dim_date (\n",
    "    \n",
    "    DateID              INTEGER,\n",
    "    Date                DATE,\n",
    "    Day                 INTEGER,\n",
    "    DayOfWeek           VARCHAR(20),\n",
    "    DayOfWeekNumber     INTEGER,\n",
    "    MonthName           VARCHAR(20),\n",
    "    MonthNumber         INTEGER,\n",
    "    Year                INTEGER,\n",
    "    YearMonth           INTEGER\n",
    "   \n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{dimDate_path}'\n",
    "\"\"\")\n",
    "\n",
    "# 3) Verify registration and schema\n",
    "spark.sql(\"SHOW TABLES\").show(truncate=False)\n",
    "spark.sql(\"DESCRIBE delta_table\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b309212-628a-437a-a7ca-cdb81510b9af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dim Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1811e307-bbc4-49cc-b49c-aefd73859f0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2) Create the table with full schema, pointing at that folder\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE stocks.gold.DimSymbol (\n",
    "    SymbolSID                BIGINT GENERATED ALWAYS AS IDENTITY(START WITH 1 increment by 1) ,\n",
    "    Symbol                   STRING,\n",
    "    ExchangeName             STRING,\n",
    "    Currency                 STRING,\n",
    "    Type                     STRING,\n",
    "    ExchangeTimeZone         STRING,\n",
    "    __CurrentFlag            BOOLEAN,\n",
    "    __DeletedFlag            BOOLEAN,\n",
    "    __EffectiveStartDateTime TIMESTAMP,\n",
    "    __EffectiveEndDateTime   TIMESTAMP,\n",
    "    __BusinessKeyHash        VARCHAR(64),\n",
    "    __Hash1Type              VARCHAR(64),\n",
    "    __Hash2Type              VARCHAR(64),\n",
    "    __CreatedBatchLogId      VARCHAR(50),\n",
    "    __UpdatedBatchLogId      VARCHAR(50),\n",
    "    __CreateDateTime         TIMESTAMP,\n",
    "    __UpdateDateTime         TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{dimSymbol_path}'\n",
    "\"\"\")\n",
    "\n",
    "# # 3) Verify registration and schema\n",
    "# spark.sql(\"SHOW TABLES\").show(truncate=False)\n",
    "# spark.sql(\"DESCRIBE dimsymbol_table\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bd55848-5658-44e2-bd9b-9b884baa176c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fact Daily Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "664563a1-48d2-40ba-89eb-882b9c829ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2) Create the table with full schema, pointing at that folder\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE stocks.gold.FactDaily (\n",
    "    \n",
    "    TransactionSID           BIGINT GENERATED ALWAYS AS IDENTITY(START WITH 1 increment by 1),\n",
    "    SymbolSID                BIGINT,\n",
    "    Volume                   INTEGER,\n",
    "    High                     DECIMAL,\n",
    "    Low                      DECIMAL,\n",
    "    Close                    DECIMAL,\n",
    "    Open                     DECIMAL,\n",
    "    DateID                   INTEGER,\n",
    "    __DeletedFlag            BOOLEAN,\n",
    "    __FactKeyHash            VARCHAR(64),\n",
    "    __CreatedBatchLogId      VARCHAR(50),\n",
    "    __CreateDateTime         TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{fact_path}'\n",
    "\"\"\")\n",
    "\n",
    "# 3) Verify registration and schema\n",
    "# spark.sql(\"SHOW TABLES\").show(truncate=False)\n",
    "# spark.sql(\"DESCRIBE delta_table\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5558112492626171,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DDLs",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
